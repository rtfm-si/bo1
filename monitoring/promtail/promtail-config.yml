# Promtail Configuration for Bo1
# Collects Docker container logs via file-based scraping (no Docker socket needed)
# https://grafana.com/docs/loki/latest/send-data/promtail/configuration/
#
# SECURITY: This config uses file-based log scraping instead of Docker socket
# Docker socket mount provides root-equivalent access - avoid in production
# Logs are read from /var/lib/docker/containers/*/*.log

server:
  http_listen_port: 9080
  grpc_listen_port: 0

positions:
  filename: /tmp/positions.yaml

clients:
  - url: http://loki:3100/loki/api/v1/push

scrape_configs:
  # Scrape WAF blocked requests log (nginx)
  # Mount /var/log/nginx from host or nginx container
  - job_name: waf-blocked
    static_configs:
      - targets:
          - localhost
        labels:
          job: waf
          __path__: /var/log/nginx/waf-blocked.log
    pipeline_stages:
      # Parse WAF log format: IP - [timestamp] "request" sqli=X xss=Y traversal=Z probe=W agent=A ua="..."
      - regex:
          expression: '^(?P<client_ip>[^ ]+) - \[(?P<timestamp>[^\]]+)\] "(?P<request>[^"]+)" sqli=(?P<sqli>\d+) xss=(?P<xss>\d+) traversal=(?P<traversal>\d+) probe=(?P<probe>\d+) agent=(?P<agent>\d+) ua="(?P<user_agent>[^"]*)"'
      - labels:
          client_ip:
          sqli:
          xss:
          traversal:
          probe:
          agent:
      - timestamp:
          source: timestamp
          format: '02/Jan/2006:15:04:05 -0700'
      # Categorize attack type for filtering
      - template:
          source: attack_type
          template: '{{ if eq .sqli "1" }}sqli{{ else if eq .xss "1" }}xss{{ else if eq .traversal "1" }}traversal{{ else if eq .probe "1" }}probe{{ else if eq .agent "1" }}scanner{{ else }}unknown{{ end }}'
      - labels:
          attack_type:

  # Scrape Docker container logs using Docker service discovery
  # This provides rich labels: container_name, compose_project, compose_service
  - job_name: docker-containers
    docker_sd_configs:
      - host: unix:///var/run/docker.sock
        refresh_interval: 30s
        filters:
          - name: status
            values: ["running"]
    relabel_configs:
      # Keep only bo1-related containers
      - source_labels: ['__meta_docker_container_name']
        regex: '/(boardofone.*|infrastructure.*)'
        action: keep
      # Extract friendly service name from container name
      - source_labels: ['__meta_docker_container_name']
        regex: '/(.+)'
        target_label: container
      # Use compose service name if available
      - source_labels: ['__meta_docker_container_label_com_docker_compose_service']
        target_label: service
      # Use compose project name
      - source_labels: ['__meta_docker_container_label_com_docker_compose_project']
        target_label: compose_project
      # Set the log path
      - source_labels: ['__meta_docker_container_id']
        target_label: __path__
        replacement: '/var/lib/docker/containers/$1/*.log'
      # Add job label
      - replacement: docker
        target_label: job
    pipeline_stages:
      # Docker json-file driver wraps logs in JSON with log, stream, time fields
      - json:
          expressions:
            log: log
            stream: stream
            docker_time: time
      - labels:
          stream:
      # Parse the inner log content (FastAPI JSON logs)
      - json:
          source: log
          expressions:
            level: level
            logger: logger
            trace_id: trace_id
            message: message
            context: context
            service: service
      # Extract error_code from log lines: [ERROR_CODE] message
      - regex:
          source: log
          expression: '\[(?P<error_code>[A-Z_]+)\]'
      # Set labels from parsed JSON
      - labels:
          level:
          logger:
          trace_id:
          service:
          error_code:
      # Use the log message as output
      - output:
          source: log
      # Add timestamp from Docker log
      - timestamp:
          source: docker_time
          format: RFC3339Nano
          fallback_formats:
            - RFC3339
            - '2006-01-02T15:04:05.999999999Z07:00'
      # Scrub sensitive data from logs (security hardening - belt and suspenders)
      # Note: Primary sanitization happens in bo1/utils/log_sanitizer.py
      # These patterns provide defense-in-depth at the log aggregation layer
      - replace:
          expression: '(?i)(password|passwd|pwd)\s*[=:]\s*[^\s,}"\'']+'
          replace: '${1}=[REDACTED]'
      - replace:
          expression: '(?i)(secret|api_key|apikey|auth_token|access_token|refresh_token|bearer)\s*[=:]\s*[^\s,}"\'']+'
          replace: '${1}=[REDACTED]'
      - replace:
          expression: '(?i)(authorization)\s*[=:]\s*(Bearer\s+)?[^\s,}"\'']+'
          replace: '${1}=[REDACTED]'
      - replace:
          expression: '(?i)(token|session_id|sessionid|csrf_token)\s*[=:]\s*[a-zA-Z0-9_\-\.]{20,}'
          replace: '${1}=[REDACTED]'
      # JSON-style sensitive keys: "password": "value" or "api_key": "value"
      - replace:
          expression: '"(password|passwd|secret|token|api_key|apikey|auth_token|access_token|refresh_token|client_secret|private_key|google_tokens|oauth_token)"\s*:\s*"[^"]*"'
          replace: '"${1}": "[REDACTED]"'
      # Email partial masking (show first 3 chars of local part)
      - replace:
          expression: '\b([a-zA-Z0-9._%+-]{1,3})[a-zA-Z0-9._%+-]*@([a-zA-Z0-9.-]+\.[a-zA-Z]{2,})\b'
          replace: '${1}***@${2}'
      # OAuth/credential keys
      - replace:
          expression: '(?i)(credential|private_key|client_secret)\s*[=:]\s*[^\s,}"\'']+'
          replace: '${1}=[REDACTED]'
      # Drop debug logs in production to reduce volume
      # Uncomment if needed:
      # - drop:
      #     expression: '.*level.*DEBUG.*'
